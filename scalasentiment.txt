//spark-shell --packages com.databricks:spark-csv_2.11:1.4.0 
val df = sqlContext.read.format("com.databricks.spark.csv").option("header","false").option("inferSchema","true").load("dayne2/combined.csv").toDF()

val df = sqlContext.read.format("com.databricks.spark.csv").option("header","false").option("inferSchema","true").load("dayne2/combined.csv").toDF()
df.printSchema() //list of columns
val polarity = sqlContext.read.format("com.databricks.spark.csv").option("header","true").option("inferSchema","true").load("dayne2/polarity.csv").toDF()

val training = sqlContext.read.format("com.databricks.spark.csv").option("header","true").option("inferSchema","true").load("dayne2/train_simple.csv").toDF()

import org.apache.spark.ml.{Pipeline, PipelineModel}
import org.apache.spark.ml.classification.LogisticRegression
import org.apache.spark.ml.feature.{HashingTF, Tokenizer}
import org.apache.spark.mllib.linalg.Vector
import org.apache.spark.sql.Row
import org.apache.spark.ml.feature.StringIndexer

val indexer = new StringIndexer().setInputCol("Label").setOutputCol("labels")

val indexed = indexer.fit(training).transform(training).toDF()
indexed.show()
val tokenizer = new Tokenizer().setInputCol("Tweets").setOutputCol("words")
val tokenized = tokenizer.transform(indexed)

import org.apache.spark.ml.feature.StopWordsRemover

val remover = new StopWordsRemover().setInputCol("words").setOutputCol("filtered")
val removed = remover.transform(tokenized)

val hashingTF = new HashingTF().setNumFeatures(1000).setInputCol("filtered").setOutputCol("features")

val data = hashingTF.transform(removed)

============ multiclass (working)


import org.apache.spark.ml.classification.{LogisticRegression, OneVsRest}
import org.apache.spark.mllib.evaluation.MulticlassMetrics
import org.apache.spark.mllib.util.MLUtils
import org.apache.spark.sql.{Row, SQLContext}

val sqlContext = new SQLContext(sc)

// parse data into dataframe
val data = MLUtils.loadLibSVMFile(sc, 
  "data/mllib/sample_multiclass_classification_data.txt")
val Array(train, test) = data.toDF().randomSplit(Array(0.7, 0.3))

// instantiate multiclass learner and train
val ovr = new OneVsRest().setClassifier(new LogisticRegression)

val ovrModel = ovr.fit(train)

// score model on test data
val predictions = ovrModel.transform(test).select("prediction", "label")
val predictionsAndLabels = predictions.map {case Row(p: Double, l: Double) => (p, l)}

sc.parallelize(Seq(model), 1).saveAsObjectFile("linReg.model")